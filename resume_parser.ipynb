{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tika\n",
        "!pip install nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK8-po1wyiIR",
        "outputId": "4655be12-346e-4e60-82b7-d453a370372d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika) (67.7.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tika) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (3.4)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32625 sha256=da3eca0e29b5230daf273496a8c011fccde90fdb67d49d2f5d117ed117000bad\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import regular expressions\n",
        "import re \n",
        "from tika import parser\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Xf-GMl62M8Ac"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = r'Pratham Shankwalker - Resume.pdf'\n",
        "file_data = parser.from_file(file)\n",
        "text = file_data['content']\n",
        "print(type(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QetLlKWzw-LA",
        "outputId": "ff035508-f725-4790-ed64-11f624b08fb0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# declare a dictionary to store all the extracted text\n",
        "extracted_text = {}"
      ],
      "metadata": {
        "id": "qC1rJPLbypBd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to extract email adress\n",
        "def get_email_addresses(string):\n",
        "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
        "    return r.findall(string)\n",
        "  \n",
        "email = get_email_addresses(text)\n",
        "print(email)\n",
        "\n",
        "extracted_text[\"E-Mail\"] = email[0]\n",
        "extracted_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS37T1MnMnjR",
        "outputId": "8213f615-cad9-4743-b520-87cc56902384"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pshankwalker1@gmail.com', 'pshankwalker1@gmail.com']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'E-Mail': 'pshankwalker1@gmail.com', 'Phone Number': ['7839453651']}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to get phone number\n",
        "def get_phone_numbers(string):\n",
        "    r = re.compile(r'(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})')\n",
        "    phone_numbers = r.findall(string)\n",
        "    return [re.sub(r'\\D', '', num) for num in phone_numbers]\n",
        "\n",
        "phone_number= get_phone_numbers(text)\n",
        "print(phone_number)\n",
        "\n",
        "#add phone number to the extracted text \n",
        "extracted_text[\"Phone Number\"] = phone_number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukUj5rqGNmmR",
        "outputId": "9c65c612-01aa-4baa-9693-36affe6a10fa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['9307051204']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# initialize matcher with a vocab\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "def extract_name(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "    \n",
        "    # First name and Last name are always Proper Nouns\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', [pattern], on_match = None)\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        return span.text\n",
        "\n",
        "name = extract_name(text)\n",
        "print(name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_7sOX1iOM4h",
        "outputId": "d838bc8d-8e25-426a-920c-453828e5035d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Github |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_skills(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "\n",
        "    # removing stop words and implementing word tokenization\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    \n",
        "    skills = [\"machine learning\",\n",
        "             \"deep learning\",\n",
        "             \"nlp\",\n",
        "             \"natural language processing\",\n",
        "             \"mysql\",\n",
        "             \"sql\",\n",
        "             \"django\",\n",
        "             \"computer vision\",\n",
        "              \"tensorflow\",\n",
        "             \"opencv\",\n",
        "             \"mongodb\",\n",
        "             \"artificial intelligence\",\n",
        "             \"ai\",\n",
        "             \"flask\",\n",
        "             \"robotics\",\n",
        "             \"data structures\",\n",
        "             \"python\",\n",
        "             \"c++\",\n",
        "             \"matlab\",\n",
        "             \"css\",\n",
        "             \"html\",\n",
        "             \"github\",\n",
        "             \"php\",\n",
        "             \"Neural Networks\",\n",
        "              \"statistics\",\n",
        "              \"Transfer Learning\"]\n",
        "            \n",
        "    skillset = []\n",
        "    \n",
        "    # check for one-grams (example: python)\n",
        "    for token in tokens:\n",
        "        if token.lower() in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    # check for bi-grams and tri-grams (example: machine learning)\n",
        "    for token in nlp_text.noun_chunks:\n",
        "        token = token.text.lower().strip()\n",
        "        if token in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
        "\n",
        "\n",
        "skills = []\n",
        "skills = extract_skills(text)\n",
        "extracted_text['skills']=skills\n",
        "skills"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-O8pxLiPLqx",
        "outputId": "6eb8e5f3-ab7d-4ecc-ca14-de689d1371e6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Github',\n",
              " 'Machine learning',\n",
              " 'Opencv',\n",
              " 'Natural language processing',\n",
              " 'Tensorflow',\n",
              " 'Data structures',\n",
              " 'Python',\n",
              " 'Mysql',\n",
              " 'C++',\n",
              " 'Sql']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Grad all general stop words\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Education Degrees\n",
        "EDUCATION = [\n",
        "            'BE','B.E.', 'B.E', 'BS', 'B.S', \n",
        "            'ME', 'M.E', 'M.E.', 'MS', 'M.S', \n",
        "            'B TECH', 'B.TECH', 'M.TECH', 'MTECH', \n",
        "            'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII'\n",
        "        ]\n",
        "\n",
        "def extract_education(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "\n",
        "    # Sentence Tokenizer\n",
        "    nlp_text = [sent.text.strip() for sent in nlp_text.sents]\n",
        "\n",
        "    edu = {}\n",
        "    # Extract education degree\n",
        "    for index, text in enumerate(nlp_text):\n",
        "        for tex in text.split():\n",
        "            # Replace all special symbols\n",
        "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
        "            if tex.upper() in EDUCATION and tex not in STOPWORDS:\n",
        "                edu[tex] = text + nlp_text[index + 1]\n",
        "\n",
        "    education = []\n",
        "    for key in edu.keys():\n",
        "        year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
        "        if year:\n",
        "            education.append((key, ''.join(year[0])))\n",
        "        else:\n",
        "            education.append(key)\n",
        "    return education\n",
        "\n",
        "education = extract_education(text)\n",
        "education\n",
        "extracted_text[\"Qualification\"] = education"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuxneDn_QnLt",
        "outputId": "11e02a4e-76a3-49b6-c102-f48e20679f93"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYeOocnKRrN4",
        "outputId": "f56c3b1f-1f10-4570-ea54-aeb373dce0f5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'E-Mail': 'pshankwalker1@gmail.com',\n",
              " 'Phone Number': ['9307051204'],\n",
              " 'Qualification': [('BE', '2024')],\n",
              " 'Institutes': ['Goa College of Engineering'],\n",
              " 'Institute': ['Goa College of Engineering'],\n",
              " 'Experience': [],\n",
              " 'skills': ['Github',\n",
              "  'Machine learning',\n",
              "  'Opencv',\n",
              "  'Natural language processing',\n",
              "  'Tensorflow',\n",
              "  'Data structures',\n",
              "  'Python',\n",
              "  'Mysql',\n",
              "  'C++',\n",
              "  'Sql']}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#college/institution\n",
        "sub_patterns = ['[A-Z][a-z]* College of Engineering','[A-Z][a-z]* Educational Institute',\n",
        "                'University of [A-Z][a-z]*',\n",
        "                'Ecole [A-Z][a-z]*']\n",
        "pattern = '({})'.format('|'.join(sub_patterns))\n",
        "matches = re.findall(pattern, text)\n",
        "\n",
        "extracted_text[\"Institute\"] = matches\n",
        "matches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxmnHkYtR3vK",
        "outputId": "6366597c-9e3e-4962-f072-e65524cce9ab"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Goa College of Engineering']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#experience\n",
        "\n",
        "sub_patterns = ['[A-Z][a-z]* [A-Z][a-z]* Private Limited','[A-Z][a-z]* [A-Z][a-z]* Pvt. Ltd.','[A-Z][a-z]* [A-Z][a-z]* Inc.', '[A-Z][a-z]* LLC',\n",
        "                ]\n",
        "pattern = '({})'.format('|'.join(sub_patterns))\n",
        "Exp = re.findall(pattern, text)\n",
        "extracted_text[\"Experience\"] = Exp\n",
        "Exp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHr8FHmjSLh1",
        "outputId": "6ca710fb-4f13-436c-ca3d-c0367e33c873"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "exOt-JH0Vb-z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}